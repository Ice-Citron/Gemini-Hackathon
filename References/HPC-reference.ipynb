{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df71887-c3a9-483f-9aa4-c2d61accfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./Gemini-Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bef62e-dedf-411c-9bb7-b9127fa7f2a5",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "❯ git config --global user.email \"shng2025@gmail.com\"\n",
    "❯ git config --global user.name \"Ice-Citron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619bb004-a2c6-4df8-8567-c3e792a4b20d",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# Installation of Python-3.11\n",
    "conda install -n base -c conda-forge python=3.11 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad44e82-81e9-495a-ae3f-02002b646537",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n skyhammer311 -c conda-forge python=3.11 -y\n",
    "conda activate skyhammer311\n",
    "which python\n",
    "\n",
    "python -m pip install -U pip\n",
    "pip install -r requirements.txt\n",
    "\n",
    "\n",
    "huggingface-cli login\n",
    "wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72796e-ff3f-4561-ae6f-f07d3d3d91d1",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create Environment\n",
    "conda create -n skyhammer_serve -c conda-forge python=3.11 -y\n",
    "\n",
    "# 2. Activate\n",
    "conda activate skyhammer_serve\n",
    "which python\n",
    "\n",
    "# 3. Install vLLM (Clean install)\n",
    "pip install -r requirements-serve.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449dc73-b704-4e31-aa12-28131d959bdf",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# Just press Enter for defaults, mostly. \n",
    "# Key choices: \n",
    "# - Multi-GPU: YES\n",
    "# - Num machines: 1\n",
    "# - Num processes: 8\n",
    "# - Mixed precision: bf16 (Since you have L40s)\n",
    "accelerate config\n",
    "\n",
    "export PYTORCH_ALLOC_CONF=expandable_segments:True\n",
    "accelerate launch --multi_gpu --num_processes=8 src/train/train_ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816b353-115f-47b1-a9e6-5c78b996b1aa",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Set Memory Management Flag     # 2. Run on Single GPU (Safe Mode)\n",
    "export PYTORCH_ALLOC_CONF=expandable_segments:True\n",
    "CUDA_VISIBLE_DEVICES=0 python src/train/train_ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1f419-d03f-4a98-9ed5-7d5fb0e20f53",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "conda deactivate\n",
    "conda remove --name skyhammer311 --all -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd889f31-98c1-4f73-9b27-edc605e7e4ad",
   "metadata": {},
   "source": [
    "# VLLM SERVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bbf14-29bc-4237-b744-e1019869673a",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "vllm serve Qwen/Qwen2.5-Coder-32B-Instruct-AWQ \\\n",
    "  --tensor-parallel-size 2 \\\n",
    "  --enable-lora \\\n",
    "  --lora-modules skyhammer=shng2025/SkyHammer-32B-v1 \\\n",
    "  --port 8000 \\\n",
    "  --api-key skyhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af484b1-ab83-4d34-a3d6-86d495890641",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "vllm serve Qwen/Qwen3-VL-32B-Instruct \\\n",
    "  --tensor-parallel-size 2 \\\n",
    "  --max-model-len 32768 \\\n",
    "  --port 8000 \\\n",
    "  --trust-remote-code \\\n",
    "  --api-key skyhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3485d32-89bc-4ba3-81c8-c86788b6a0f0",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "huggingface-cli download unsloth/GLM-4.7-GGUF \\\n",
    "  --include \"Q4_K_M/*\" \\\n",
    "  --local-dir models/ \\\n",
    "  --local-dir-use-symlinks False\n",
    "\n",
    "\n",
    "# pip install \"llama-cpp-python[server]\"\n",
    "CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install --upgrade --force-reinstall --no-cache-dir llama-cpp-python[server]\n",
    "\n",
    "python -m llama_cpp.server \\\n",
    "  --model models/Q4_K_M/GLM-4.7-Q4_K_M-00001-of-00005.gguf \\\n",
    "  --n_gpu_layers -1 \\\n",
    "  --n_ctx 32768 \\\n",
    "  --port 8000 \\\n",
    "  --api_key skyhammer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a31978-2f0d-43ff-81ed-e4f04f501ca9",
   "metadata": {},
   "source": [
    "# Unsloth Trial\n",
    "\n",
    "### FUCKING STUPID READ THE DOCUMENTATIONS NEXT TIME BAHAHAHAHAHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad53d8-bd8e-4da7-8b4f-a056b3a56964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clean up potential conflicts\n",
    "pip uninstall -y transformers unsloth unsloth_zoo tokenizers\n",
    "\n",
    "# 2. Install the Official Mistral Tokenizer Backend (The key from your docs!)\n",
    "pip install --upgrade mistral-common>=1.5.5\n",
    "\n",
    "# 3. Install Standard Training Support\n",
    "pip install bitsandbytes accelerate peft sentencepiece protobuf datasets hf_transfer\n",
    "\n",
    "# 4. Install the Experimental Transformers (Required for 'ministral3' model support)\n",
    "pip install \"git+https://github.com/huggingface/transformers.git@bf3f0ae70d0e902efab4b8517fce88f6697636ce\"\n",
    "\n",
    "# 5. Install Tokenizers (Updated to match the experimental transformers)\n",
    "pip install --upgrade \"tokenizers>=0.21.0\"\n",
    "\n",
    "# 6. Install Unsloth & TRL (No dependencies to avoid downgrading transformers)\n",
    "pip install --no-deps \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\" unsloth_zoo trl==0.22.2\n",
    "\n",
    "\n",
    "########\n",
    "pip uninstall -y torchao\n",
    "# pip install deepspeed==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58825cb2-2b55-4e21-92ea-a883eab28a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python src/train/train_zero3_devstral.py\n",
    "\n",
    "\n",
    "# Set timeouts to 2 hours (7200 seconds) to prevent \"False Alarm\" kills\n",
    "export TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC=7200\n",
    "export NCCL_TIMEOUT=7200\n",
    "export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "accelerate launch src/train/train_zero3_devstral.py\n",
    "\n",
    "accelerate launch src/train/train_fsdp_24b.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
